
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_EMBEDDING_MODEL = "nomic-embed-text"
OLLAMA_LLM_MODEL="llama3.2"
VECTOR_DB_HOST=localhost
VECTOR_DB_URL=http://localhost:6333
VECTOR_DB_COLLECTION=rag_docs
# Configurações RAG
CHUNK_SIZE=800
CHUNK_OVERLAP=200
DEFAULT_TOP_K=5
ENABLE_RERANKING=false

# Configurações API
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=DEBUG
LANGFUSE_SECRET_KEY = 
LANGFUSE_PUBLIC_KEY = 
LANGFUSE_BASE_URL = "https://cloud.langfuse.com"